## 乐购商城开发文档

## 分布式基础概念

**1. 微服务**

拒绝大型单体应用，基于业务进行服务微化拆分，各个服务独立部署运行。

**2. 分布式，集群，节点**

分布式中的每一个节点，都可以做集群。
集群并不一定是分布式的。
节点是集群中的一个服务器。

**3. 远程调用**

HTTP + JSON

**4. 负载均衡**

- **轮询**：请求依次选择服务器，直至最后一台服务器，然后循环。
- **最小连接**：优先选择连接数最少即压力最小的服务器。
- **散列**：根据请求源的IP的散列来选择服务器。

**5. 服务注册与发现中心**

**6. 配置中心**

集中管理微服务的配置信息

**7. 服务熔断，服务降级**

- **服务熔断**：设置服务的超时，当被调用的服务经常失败到达某个阈值，可以开启断路保护机制，后来的请求不再去调用该服务。本地直接返回默认的数据。
- **服务降级**：运维期间，当系统处于高峰期，系统资源紧张，可以让非核心的业务降级运行。

**降级**：某些服务不处理或者简单处理（抛异常、返回NULL、调用Mock数据、调用Fallback处理逻辑）

**8. API 网关**

抽象微服务中都需要的公共功能，提供客户端负载均衡，服务自动熔断，灰度发布，统一认证，限流流控，日志统计等丰富的功能。

## 1. 项目简介

**乐购商城是一套完善的微服务电商系统，由前台商城系统和后台管理系统构成，基于SpringBoot、SpringCloud、SpringCloud alibaba、Vue实现，采用前后端分离开发模式。前台商城系统具有首页门户、商品推荐、商品检索、商品详情、用户中心、购物车、订单流程、支付、秒杀等功能，后台管理系统具有控制面板、统计管理、商品系统、用户系统、订单系统、库存系统、优惠系统、内容管理、系统管理等模块。**

涵盖**Restful接口**、**数据校验**、**网关**、**注册发现**、**配置中心**、**熔断**、**限流**、**降级**、**链路追踪**、**性能监控**、**压力测试**、**系统预警**、**集群部署**、**持续集成**、**持续部署等技术点**，均采用当前最流行的技术栈。

### 1.1 项目架构

#### 1.1.1 系统架构图

![](E:\程序人生\个人学习笔记\学习笔记图床\乐购商城微服务架构图.jpg)

#### 1.1.2 服务划分图

![](E:\程序人生\个人学习笔记\学习笔记图床\服务划分图.png)



![](E:\程序人生\个人学习笔记\学习笔记图床\乐购服务划分图.png)

#### 1.1.3 模块说明

```
|-- tesco
    |-- tesco-admin -- 后台管理系统后端
    |-- tesco-admin-vue -- 后台管理系统前端
    |-- tesco-api -- 各个微服务的API接口
    |   |-- tesco-cart-api
    |   |-- tesco-coupon-api
    |   |-- tesco-goods-api
    |   |-- tesco-order-api
    |   |-- tesco-search-api
    |   |-- tesco-seckill-api
    |   |-- tesco-third-api
    |   |-- tesco-user-api
    |   |-- tesco-ware-api
    |-- tesco-cart -- 购物车微服务
    |-- tesco-common -- 通用工具类
    |-- tesco-coupon -- 优惠微服务
    |-- tesco-database -- 数据库表
    |-- tesco-dependency -- 核心依赖包
    |-- tesco-gateway -- 网关微服务（分为管理员、用户、游客三个急别）
    |   |-- tesco-gateway-system
    |   |-- tesco-gateway-user
    |   |-- tesco-gateway-web
    |-- tesco-goods -- 商品微服务
    |-- tesco-oauth2 -- 认证微服务
    |-- tesco-order -- 订单微服务
    |-- tesco-search -- 检索微服务
    |-- tesco-seckill -- 秒杀微服务
    |-- tesco-third-services -- 第三方接口服务
    |-- tesco-user -- 用户微服务
    |-- tesco-ware -- 库存微服务
```

### 1.2 技术选型

#### 1.2.1 后端技术

| 技术                          | 说明                           |
| ----------------------------- | ------------------------------ |
| Spring Boot                   | 容器+MVC框架                   |
| MyBatis                       | ORM框架                        |
| MyBatis Plus                  | MyBatis增强工具                |
| MySql                         | 数据库                         |
| Redis                         | 分布式缓存                     |
| RabbitMQ                      | 消息中间件                     |
| Elasticsearch                 | 搜索引擎                       |
| Kibana                        | Elasticsearch可视化工具        |
| LogStash                      | 日志收集工具                   |
| Redisson                      | 分布式锁框架                   |
| SpringCache                   | 简化分布式缓存开发             |
| JSR303                        | 数据校验                       |
| Lombok                        | 简化对象封装工具               |
| Nginx                         | 反向代理、限流、负载均衡、容错 |
| Docker                        | 虚拟化容器技术                 |
| Kubernetes                    | 容器管理、集群部署             |
| Jenkins                       | 持续集成                       |
| AlipayTemplate                | 支付宝支付                     |
| Spring Cloud Gateway          | API 网关                       |
| Spring Cloud Security+Oauth2  | 安全认证授权、第三方登录       |
| Spring Cloud OpenFeign        | 服务消费（远程调用）           |
| Spring Cloud Ribbon           | 服务消费（负载均衡）           |
| Spring Cloud Sleuth+Zipkin    | 分布式链路追踪及可视化         |
| Spring Cloud Alibaba Nacos    | 服务发现与注册、分布式配置中心 |
| Spring Cloud Alibaba Sentinel | 服务容错（限流、熔断、降级）   |
| Spring Cloud Alibaba OSS      | 阿里云对象存储服务             |
| Spring Cloud Alibaba Seata    | 分布式事务解决方案             |
| Spring Cloud Alibaba SMS      | 短信服务                       |

#### 1.2.2 前端技术

| 技术         | 说明               |
| ------------ | ------------------ |
| Vue          | 前端框架           |
| Vue-router   | 路由管理器         |
| Element UI   | 前端UI框架         |
| Axios        | 前端HTTP框架       |
| V-Charts     | 前端图表框架       |
| HTML CSS JS  | 前端技术           |
| ECMAScript 6 | JavaScript语言标准 |
| JQuery       | JS插件库           |
| Thymeleaf    | 模板引擎           |

### 1.3 开发环境

| 工具                          | 版本号   |
| ----------------------------- | -------- |
| JDK                           | 1.8      |
| MySql                         | 5.7.22   |
| Redis                         | 5.0      |
| RabbitMQ                      | 3.8.2    |
| Elasticsearch                 | 7.4.2    |
| Kibana                        | 7.4.2    |
| LogStash                      | 7.4.2    |
| Nginx                         | 1.17.10  |
| Docker                        | 19.03.05 |
| Zipkin                        | 2.22.2   |
| Spring Cloud Alibaba Nacos    | 1.1.14   |
| Spring Cloud Alibaba Sentinel | 1.8.0    |
| Spring Cloud Alibaba Seata    | 0.9.0    |

### 1.4 开发工具

| 工具         | 说明              |
| ------------ | ----------------- |
| IDEA         | Java代码编译环境  |
| VsCode       | 前端代码编辑器    |
| VMware       | 虚拟机管理        |
| Navicat      | 数据库可视化工具  |
| RedisManager | 缓存可视化工具    |
| Postman      | 接口调试工具      |
| Xshell       | Linux远程连接工具 |
| Xftp         | 数据传输工具      |
| SwitchHosts  | 本地Host管理      |
| ApacheJMeter | 压力测试工具      |
| 花生壳       | 内网穿透工具      |
| Notepad      | 好用的记事本      |

## 2. 正式进入开发

### 2.1 基础篇开发（后台管理系统）

- **2.1.1 基于 Docker安装 Mysql、Redis、Nacos**
- **2.1.2 整合OSS阿里云对象存储**
- **2.1.3 JSR303数据校验**

```
 *   1）、给Bean添加校验注解:javax.validation.constraints，并定义自己的message提示
 *   2)、开启校验功能@Valid
 *      效果：校验错误以后会有默认的响应；
 *   3）、给校验的bean后紧跟一个BindingResult，就可以获取到校验的结果
 *   4）、分组校验（多场景的复杂校验）
 *         1)、	@NotBlank(message = "品牌名必须提交",groups = {AddGroup.class,UpdateGroup.class})
 *          给校验注解标注什么情况需要进行校验
 *         2）、@Validated({AddGroup.class})
 *         3)、默认没有指定分组的校验注解@NotBlank，在分组校验情况@Validated({AddGroup.class})下不生效，只会在@Validated生效；
 *
 *   5）、自定义校验
 *      1）、编写一个自定义的校验注解
 *      2）、编写一个自定义的校验器 ConstraintValidator
 *      3）、关联自定义的校验器和自定义的校验注解
 *      @Documented
 *      @Constraint(validatedBy = { ListValueConstraintValidator.class【可以指定多个不同的校验器，适配不同类型的校验】 })
 *      @Target({ METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE })
 *      @Retention(RUNTIME)
 *      public @interface ListValue {}
```

### 2.2 高级篇开发

#### 2.2.1 ES+Kibana

- **部署 ES**

```
docker run --name elasticsearch -p 9200:9200 -p 9300:9300 \
-e "discovery.type=single-node" \
-e ES_JAVA_OPTS="-Xms64m -Xmx512m" \
-v /usr/local/docker/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \
-v /usr/local/docker/elasticsearch/data:/usr/share/elasticsearch/data \
-v /usr/local/docker/elasticsearch/plugins:/usr/share/elasticsearch/plugins \
-d elasticsearch:7.4.2
```

设置elasticsearch目录的权限

```
chmod -R 777 /usr/local/docker/elasticsearch/
```

- **部署 Kibana**

```
docker run --name kibana -e ELASTICSEARCH_HOSTS=http://192.168.75.154:9200 -p 5601:5601 -d kibana:7.4.2
```

- **IK分词器**

```
# 安装
wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.4.2/elasticsearch-analysis-ik-7.4.2.zip

# 解压
unzip elasticsearch-analysis-ik-7.4.2.zip

rm -fr elasticsearch-analysis-ik-7.4.2.zip
```

#### 2.2.2 Nginx

```
# 提前创建好目录结构
mkdir /usr/local/docker/nginx/conf -p
mkdir /usr/local/docker/nginx/html
mkdir /usr/local/docker/nginx/logs

# 启动一个nginx示例（只为复制出配置）
docker run -p 80:80 --name nginx -d nginx

# 拷贝容器内的配置文件到当前目录（/usr/local/docker/nginx/conf）
docker container cp nginx:/etc/nginx .

#优化目录结构
mv * ../
rm -fr nginx

# 删除原容器
docker rm -f nginx

# 创建新的容器
docker run -p 80:80 --name nginx \
-v /usr/local/docker/nginx/html:/usr/share/nginx/html \
-v /usr/local/docker/nginx/logs:/var/log/nginx \
-v /usr/local/docker/nginx/conf:/etc/nginx \
-d nginx
```

- **反向代理**
- **负载均衡**
- **坑**

**nginx代理给网关时，会丢失请求的host信息**

解决方法：

```
proxy_set_header Host $host
```

#### 2.2.3 性能

**性能考虑点：**

数据库、应用程序、中间件（tomcat、nginx）、网络和操作系统等方面 **CPU密集型**
**IO密集型**

**JMeter使用过程中出现的一些问题（略）**

JMeter Address Already in use 错误解决：

windows本身提供的端口访问机制问题。

windows提供给TCP/IP链接的端口为1024-5000，并且要四分钟来循环回收他们。导致我们在短时间内跑大量的请求是端口被占满了。

解决：

1.cmd中，用regedit命令打开注册表

2.在 HKEY_LOCAL_MACHINE\SYSTEM\CurrentControllerSet\Services|Tcpip\Parameters下

​	右击parameters,添加一个新的DWORD，名字为MaxUserPort

​	双击MaxUserPort，输入数值数据为65534，技术选择十进制（如果是分布式运行的话，控制机器和负载机器都需要这样操作）

3.修改完毕之后重启机器才会生效。

**一丶监控**

1. jvm内存模型（以后单独学习）
2. 堆内存与垃圾回收
3. jvisualvm使用 （注意使用与java版本匹配的地址）

**二丶优化**

- **中间件**

中间件越多，性能损失越大，大多都损失在网络交互上 。

解决方案：优化中间件，提高中间件的吞吐量；提高传输效率（网卡，网线，传输协议，传输技术等）

- **业务（优化重点）**

数据库 模板渲染速度 静态资源

解决方案：优化Mysql，为字段添加索引，降低日志级别；开启模板引擎的缓存

- **Nginx动静分离**

1. 将所有项目的静态资源都放在Nginx中
2. 规则：/static/**所有请求都由Nginx直接返回

- **线上应用内存奔溃宕机情况**

#### 2.2.4 缓存

##### 一丶本地缓存（不适用分布式场景）

问题：

1. 分布式场景下，同一服务的不同服务器，要分别进行缓存；
2. 数据发生修改时，同一服务的不同服务器，会出现数据不统一的情况。

##### 二丶分布式缓存（集中式的缓存中间件）

**Redis缓存**

1. 缓存中存储的数据都是Json字符串
2. Json跨语言、跨平台兼容
3. 序列化与反序列化（往Json中放字符串，拿出的字符串，需要逆转成所需的对象类型）

**高并发下缓存失效问题**

- **穿透**

高并发查询不存在的数据，数据库瞬时压力增大，导致崩溃。

解决方案：缓存null结果，并加入短暂过期时间。

- **雪崩**

缓存的数据大面积同时失效的时候迎来高并发。

解决方案：失效时间增加随机值，降低缓存过期时间的重复率。

- **击穿**

某一个高频热点数据失效的时候迎来高并发。

解决方案：加锁，只让一个人去查数据库，其他人等待查缓存。

**如何更好的实现加锁**

- **本地锁**

只能锁住当前进程，无法锁住所有

单体应用加锁后仍查询多次数据库的原因：

线程1查询数据库 -> 线程1释放锁 -> 线程2占用锁 -> 线程2确认无缓存 -> 线程2查询数据库 -> 线程1将数据放入缓存

（通俗说，线程1还没来得及放缓存，线程2已经进行了查询）

解决方案：

先将数据放入缓存，再释放锁。

- **分布式锁**

**常见问题及解决方法：**

1. 死锁 ---> 设置锁的自动过期时间
2. 业务超时，误删其他业务锁 ---> 设置uuid

lua脚本解锁（原子操作）

**加锁，解锁都要保证操作的原子性**

##### 三丶分布式锁框架 - Redisson

- **lock锁（阻塞式等待）**

特点：

1. 业务超时，运行期间，锁自动续期，默认30s（看门狗原理）
2. 业务运行完成，无需手动解锁，30s后自动删除

```
lock.lock();    //可以自动续期（看门狗的时间/3=10s）

lock.lock(10, TimeUnit.SECONDS);    //不能自动续期，自动解锁时间一定要大于业务运行时间

boolean res = lock.tryLock(100, 10, TimeUnit.SECONDS);  //尝试加锁，最多等待100秒，上锁以后10秒自动解锁

fairLock.lock(10, TimeUnit.SECONDS);    //公平锁
```

推荐使用 明确指定超时时间 的方法，但超时时间不能太小

- **读写锁**

```
RReadWriteLock rwlock = redisson.getReadWriteLock("anyRWLock");
// 最常见的使用方法
rwlock.readLock().lock();
// 或
rwlock.writeLock().lock();
```

**读数据加读锁（共享锁），改数据加写锁（互斥锁、独享锁）**

读+读：相当于无锁，并发读
写+读：等待写锁释放
写+写：阻塞方式
读+写：有读锁，写需要等待

**总：只要有写锁的存在，都需要等待**

- **信号量**

**可以用作分布式限流**

```
RSemaphore semaphore = redisson.getSemaphore("semaphore");
semaphore.acquire();    //获取一个信号（车位）
semaphore.acquireAsync();
semaphore.acquire(23);
semaphore.tryAcquire(); //尝试获取
semaphore.tryAcquireAsync();
semaphore.tryAcquire(23, TimeUnit.SECONDS);
semaphore.tryAcquireAsync(23, TimeUnit.SECONDS);

semaphore.release(10);
semaphore.release();    //释放一个信号（车位）
semaphore.releaseAsync();
```

场景：停车

- **闭锁**

```
RCountDownLatch latch = redisson.getCountDownLatch("anyCountDownLatch");
latch.trySetCount(1);
latch.await();

// 在其他线程或其他JVM里
RCountDownLatch latch = redisson.getCountDownLatch("anyCountDownLatch");
latch.countDown();
```

场景：学校锁门（所有班级锁门，再锁大门）

##### 四丶缓存数据的一致性问题

- **双写模式**

更新数据库，同时更新缓存

- **失效模式**

更新数据库，删除缓存

问题：脏数据 解决方法：加锁 ---> 系统比较笨重

[缓存一致性]

[Canal]

##### 五丶SpringCache（简化缓存开发）

- **引入依赖**

```
    <!-- SpringCache -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-cache</artifactId>
    </dependency>
```

- **默认行为**

1. 如果缓存中有，不调用方法
2. key自动生成 ---> `缓存名称::SimpleKey []`
3. 缓存的value值，默认使用jdk序列化机制，将序列化后的数据保存到redis
4. 默认ttl=-1，即永不过期

- **自定义配置**

1. 指定缓存的key
2. 指定缓存的存活时间
3. 将数据保存为json

```
# 使用redis作为缓存
spring.cache.type=redis
# 存活时间（毫秒为单位，1小时）
spring.cache.redis.time-to-live=3600000
# 前缀，方便区分（若不指定前缀，默认使用缓存的名字作为前缀）
#spring.cache.redis.key-prefix=CACHE_
# 是否启用前缀
spring.cache.redis.use-key-prefix=true
# 是否缓存空值，防止缓存穿透
spring.cache.redis.cache-null-values=true
package com.jerusalem.goods.config;

import org.springframework.boot.autoconfigure.cache.CacheProperties;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.boot.context.properties.EnableConfigurationProperties;
import org.springframework.cache.annotation.EnableCaching;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.cache.RedisCacheConfiguration;
import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.RedisSerializationContext;
import org.springframework.data.redis.serializer.StringRedisSerializer;

/****
 * SpringCache - 自定义缓存配置
 * @Author: jerusalem
 * @Description: MyCacheConfig
 * @Date 2020/6/24 14:58
 *****/
@EnableConfigurationProperties(CacheProperties.class)       //开启与配置文件的绑定功能
@Configuration
@EnableCaching      //开启缓存
public class MyCacheConfig {

    @Bean
    RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties){

        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig();
        config = config.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));
        config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));

        CacheProperties.Redis redisProperties = cacheProperties.getRedis();
        /**
         * 引入配置文件中的配置信息
         */
        if (redisProperties.getTimeToLive() != null) {
            config = config.entryTtl(redisProperties.getTimeToLive());
        }
        if (redisProperties.getKeyPrefix() != null) {
            config = config.prefixKeysWith(redisProperties.getKeyPrefix());
        }
        if (!redisProperties.isCacheNullValues()) {
            config = config.disableCachingNullValues();
        }
        if (!redisProperties.isUseKeyPrefix()) {
            config = config.disableKeyPrefix();
        }
        return config;
    }
}
```

- **常用注解**

```
@Cacheable
将数据保存到缓存

@CacheEvict
将数据从缓存中删除

@CachePut
更新缓存（不影响方法执行）

@Caching
组合多个缓存操作

@CacheConfig
在类级别，共享缓存的相同配置
```

**原理与不足：**

- 读模式：

1. 穿透：查询null数据

解决方案：缓存空值

1. 击穿：大量并发查询一个正好过期的数据

解决方案：默认无加锁，只有查询的时候可加同步锁

1. 雪崩：大量的key同时过期

解决方案：加过期时间

- 写模式（缓存、数据库一致性问题）
  1）、读写加锁
  2）、引入Canal，监控数据库的更新
  3）、读多写少，直接去数据库查询

**总结：**

**常规数据（读多写少，即时性，一致性要求不高的数据）：适合使用SpringCache**

**特殊数据：特殊设计**

#### 2.2.5 SpringSession

##### Session共享问题解决-不同服务，子域session共享（整合redis存储session）

**核心原理：**

**装饰者模式**

**@EnableRedisHttpSession 导入RedisHttpSessionConfiguration配置**

1. 给容器添加了一个组件RedisIndexedSessionRepository -》redis操作session的增删改查
2. SessionRepositoryFilter ==》 Filter：session存储过滤器，每个请求都必须经过filter

- 创建时，自动从容器中获取到了SessionRepository
- 原始的request,response都被包装（SessionRepositoryRequestWrapper）
- 以后获取session（request。getSession）
- wrappedRequest.getSession();

自动延期：redis中的数据也是有过期时间的

#### 2.2.6 幂等性问题

**简介：**

​		接口幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生副作用。

​		比如，支付场景，用户购买了商品支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额返发现多扣钱了，流水记录也变成了两条，这就没有保证接口的幂等性。

**场景：**
用户多次点击按钮
用户页面回退再次提交
微服务互相调用，由于网络问题，导致请求失败，feign触发重试机制
其他业务情况

**幂等性解决方案：**

- **token机制**

  1、服务端提供了发送token的接口。我们在分析业务的时候，哪些业务是存在幂等问题的，就必须在执行业务前，先去获取token，	  服务器会把token保存到redis中。
  2、然后调用业务接口请求时，把token携带过去，一般放在请求头部。
  3、服务器判断 token 是否存在 redis中，存在表示第一次请求，然后删除 token,继续执行业务。
  4、如果判断 token 不存在 redis中，就表示是重复操作，直接返回重复标记给 client，这样就保证了业务代码，不被重复执行。

  危险性：

  1、先删除 token 还是后删除 token;
  (1)先删除可能导致，业务确实没有执行，重试还带上之前token，由于防重设计导致，请求还是不能执行。
  (2)后删除可能导致，业务处理成功，但是服务闪断，出现超时，没有删除token，别人继续重试，导致业务被执行两边
  (3)我们最好设计为先删除token，如果业务调用失败，就重新获取token再次请求。
  2、Token 获取、比较和删除必须是原子性
  (1) redis.get(token)、token.equals、redis.del(token)如果这两个操作不是原子，可能导致，高并发下，都get到同样的数据，判断都成功，继续业务并发执行
  (2)可以在 redis 使用lua脚本完成这个操作
  if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end

- **锁机制**

  - 数据库悲观锁
    select * from xxxx where id = 1 for update;
    悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，需要根据实际情况选用。另外要注意的是，id字段一定是主键或者唯一索引，不然可能造成锁表的结果，处理起来会非常麻烦。
  - 数据库乐观锁
    这种方法适合在更新的场景中(update t_goods set count = count -1, version = version + 1 where good_id=2 and version = 1)根据 version 版本，也就是在操作库存前先获取当前商品的 version 版本号，然后操作的时候带上此 version 号。我们梳理下，我们第一次操作库存时，得到 version 为1，调用库存服务version 变成了 2；但返回给订单服务出现了问题，订单服务又一次发起调用库存服务，当订单服务传如的 version 还是1，再执行上面的 sql语句时，就不会执行；因为 version 已经变为2了，where条件就不成立。这样就保证了不管调用几次，只会真正的处理一次。乐观锁主要用于处理读多写少的问题。
  - 业务层分布式锁
    如果多个机器可能在同一时间同时处理相同的数据，比如多台机器定时任务都拿到了相同数据处理，我们就可以加分布式锁，锁定此数据，处理完成后释放锁。获取到锁的必须先判断这个数据是否被处理过。

- **各种唯一约束**

  - 数据库唯一约束
    插入数据，应该按照唯一索引进行插入，比如订单号，相同的订单就不可能有两条记录插入。我们在数据库层面防止重复。
    这个机制是利用了数据库的主键唯一约束的特性，解决了在insert 场景时幂等问题。但主键的要求不是自增的主键，这样就需要业务生成全局唯一的主键。
    如果是分库分表场景下，路由规则要保证相同请求下，落地在同一个数据库和同一表中，要不然数据库主键约束就不起效果了，因为是不同的数据库和表主键不相关。
  - redis set 防重
    很多数据需要处理，只能被处理一次，比如我们可以计算数据的MD5将其放入redis的set，每次处理数据，先看这个MD5是否已经存在，存在就不处理。
  - 防重表
    使用订单号orderNo 做为去重表的唯一索引，把唯一索引插入去重表，再进行业务操作，且他们在同一个事务中。这个保证了重复请求时，因为去重表有唯一约束，导致请求失败，避免了幂等问题。这里要注意的是，去重表和业务表应该在同一库中，这样就保证了在同一个事务，即使业务操作失败了，也会把去重表的数据回滚。这个很好的保证了数据一致性。
    之前说的 redis 防重也算。
  - 全局请求唯一id
    调用接口时，生成一个唯一id，redis 将数据保存到集合中(去重)，存在即处理过。可以使用nginx设置每一个请求的唯一id；
    （proxy_set_header X-Request-ld $request_id）

#### 2.2.7 本地事务

**1、事务的基本性质**
数据库事务的几个特性：原子性(Atomicity】、一致性(Consistency)、隔离性或独立性(Isolation)和持久性(Durabilily)，简称ACID。

- 原子性，一系列的操作整体不可拆分，要么同时成功，要么同时失败
- 一致性：数据在事务的前后，业务整体一致。
- 隔离性：事务之间互相隔离。
- 持久性：一旦事务成功，数据一定会落盘在数据库。

**2、事务的隔离级别** 

- READ UNCOMMITTED(读未提交)
  该隔离级别的事务会读到其它未提交事务的数据，此现象也称之为脏读。
- READ COMMITTED(读提交)
  一个事务可以读取另一个已提交的事务，多次读取会造成不一样的结果，此现象称为不可重复读问题，Oracle和SQLServer的默认隔离级别。
- REPEATABLE READ(可重复读)
  该隔离级别是 MySQL 默认的隔离级别，在同一个事务里，select 的结果是事务开始时时间点的状态，因此，同样的 select 操作读到的结果会是一致的，但是，会有幻读现象。MySQL的！nnoDB引擎可以通过 next-keylocks 机制(参考下文"行锁的算法”一节)来避免幻读。
- SERIALIZABLE(序列化)
  在该隔离级别下事务都是串行顺序执行的，MySQL 数据库的 InnoDB 引擎会给读操作隐式 xueyuan.com冲(加一把读共享锁，从而避免了脏读、不可重读复读和幻读问题。

**3、事务的传播行为**

- PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。
- PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。
- PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。
- PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。
- PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
- PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。
- PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。

#### 2.2.8 分布式事务

**场景：**

分布式系统经常出现机器宕机、网络异常、消息丢失、消息乱序、数据错误、不可靠TCP、存储数据丢失等异常。

**核心理论：**
1、CAP定理
CAP原则又称CAP定理，指的是在一个分布式系统中，下面三个要素最多只能同时实现两点，不可能三者兼顾。一般来说，分区容错无法避免，因此可以认为CAP的P总是成立。CAP定理告诉我们，剩下的C和A无法同时做到。[分布式系统中实现一致性的算法](http://thesecretlivesofdata.com/raft/)

- 一致性(Consistency)
  在分布式系统中的所有数据备份，在同一时刻是否同样的值。(等同于所有节点访
  问同一份最新的数据副本)
- 可用性(Availability)
  在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。(对数据
  更新具备高可用性)
- 分区容错性(Partition tolerance)
  大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区(partition)。分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。


2、面临的问题
对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到99.99999%(N个9)，即保证p和A，舍弃C。
3、BASE 理论
BASE理论是对CAP理论的延伸，思想是即使无法做到强一致性(CAP的一致性是强一致性)，但可以适当的采用弱一致性，即**最终一致性**。

- 基本可用（Basically Available)
  基本可用是指分布式系统在出现故障的时候，允许损失部分可用性(例如响应时间、功能上的可用性)，允许损失部分可用性。需要注意的是，基本可用绝不等价于系统不可用。
  - 响应时间上的损失：正常情况下搜索引擎需要在0.5 秒之内返回给用户相应的查询结果，但由于出现故障(比如系统部分机房发生断电或断网故障)，查询结果的响应时间增加到了1~2秒。
  - 功能上的损失：购物网站在购物高峰(如双十一)时，为了保护系统的稳定性，部分消费者可能会被引导到一个降级页面。

- 软状态( SoftState)
  软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据会有多个副本，允许不同副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。
- 最终一致性( Eventual Consistency)
  最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。

4、强一致性、弱一致性、最终一致性
从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。如果能容忍后续的部分或者全部访问不到，则是弱一致性。如果经过一段时间后要求能访问到更新后的数据，则是最终一致性。

**分布式事务的解决方案：**

1. 2PC模式
数据库支持的2PC【2 phase commit】，又叫做XA Transactions。MySQL从5.5版本开始支持，SQLServer2005开始支持，Oracle7开始支持。
其中，XA是一个两阶段提交协议，该协议分为以下两个阶段：
第一阶段：事务协调器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是否可以提交
第二阶段：事务协调器要求每个数据库提交数据。其中，如果有任何一个数据库否决此次提交，那么所有数据库都会被要求回滚它们

- XA协议比较简单，而且一旦商业数据库实现了XA协议，使用分布式事务的成本也比较低。
- XA性能不理想，特别是在交易下单链路，往往并发量很高，XA无法满足高并发场景
- XA目前在商业数据库支持的比较理想，在mysql数据库中支持的不太理想，mysql的XA实现，没有记录prepare阶段日志，主备切换回导致主库与备库数据不一致。
- 许多nosql也没有支持XA，这让XA的应用场景变得非常狭隘。
- 也有3PC，引入了超时机制(无论协调者还是参与者，在向对方发送请求后，若长时间未收到回应则做出相应处理)

2. 柔性事务-TCC 事务补偿型方案
   刚性事务：遵循ACID原则，强一致性。
   柔性事务：遵循BASE理论，最终一致性；
   与刚性事务不同，柔性事务允许一定时间内，不同节点的数据不一致，但要求最终一致。
   柔性事务：遵循 BASE 理论，最终一致性；
   与刚性事务不同，柔性事务允许一定时间内，不同节点的数据不一致，但要求最终一致。

   一阶段prepare 行为：调用 自定义的 prepare 逻辑。
   二阶段 commit 行为：调用 自定义的 commit 逻辑。
   二阶段rollback 行为：调用 自定义 的 rollback 逻辑。
   所谓TCC模式指支持把 自定义的分古事各纳入到全局事备的管理中。

3. 柔性事务-最大努力通知型方案
   按规律进行通知，**不保证数据一定能通知成功，但会提供可查询操作接口进行核对**。这种方案主要用在与第三方系统通讯时，比如：调用微信或支付宝支付后的支付结果通知。这种方案也是结合MQ进行实现，例如：通过MQ发送http请求，设置最大通知次数。达到通知次数后即不再通知。
   案例：银行通知、商户通知等(各大交易业务平台间的商户通知：多次通知、查询校对、对账文件)，支付宝的支付成功异步回调

4. 柔性事务-可靠消息+最终一致性方案(异步确保型)
   实现：业务处理服务在业务事务提交之前，向实时消息服务请求发送消息，实时消息服务只记录消息数据，而不是真正的发送。业务处理服务在业务事务提交之后，向实时消息服务确认发送。只有在得到确认发送指令后，实时消息服务才会真正发送。

#### 2.2.9 RabbitMq

```
docker run -d --name rabbitmq -p 5671:5671 -p 5672:5672 -p 4369:4369 -p 25672:25672 -p 15671:15671 -p 15672:15672 985adbf13062
```

**1、RabbitMQ延时队列(实现定时任务)**
场景：
比如未付款订单，超过一定时间后，系统自动取消订单并释放占有物品。
常用解决方案：
spring的 schedule 定时任务轮询数据库
缺点：
消耗系统内存、增加了数据库的压力、存在较大的时间误差
解决：rabbitmq的消息TTL和死信Exchange结合

- **Dead Letter Exchanges (DLX)**
  一个消息在满足如下条件下，会进死信路由，记住这里是路由而不是队列，一个路由可以对应很多队列。（什么是死信)

  - 一个消息被Consumer拒收了，并且reject方法的参数里requeue是false。也就是说不会被再次放在队列里，被其他消费者使用。(basic.reject/ basic.nack) requeue=false
  - 上面的消息的TTL到了，消息过期了。
  - 队列的长度限制满了。排在前面的消息会被丢弃或者扔到死信路由上

  Dead Letter Exchange其实就是一种普通的exchange，和创建其他exchange没有两样。只是在某一个设置Dead Letter Exchange的队列中有消息过期了，会自动触发消息的转发，发送到Dead Letter Exchange中去。

  我们既可以控制消息在一段时间后变成死信，又可以控制变成死信的消息被路由到某一个指定的交换机，结合二者，其实就可以实现一个延时队列。

- 消息的TTL(Time To Live)
  - 消息的TTL就是消息的存活时间。
  - RabbitMQ可以对队列和消息分别设置TTL。
    - 对队列设置就是队列没有消费者连着的保留时间，也可以对每一个单独的消息做单独的设置。超过了这个时间，我们认为这个消息就死了，称之为死信。
    - 如果队列设置了，消息也设置了，那么会取小的。所以一个消息如果被路由到不同的队列中，这个消息死亡的时间有可能不一样(不同的队列设置)。这里单讲单个消息的TTL，因为它才是实现延迟任务的关键。可以通过设置消息的expiration字段或者x-message-ttl属性来设置时间，两者是一样的效果。

![QQ图片20201112175118](E:\程序人生\个人学习笔记\学习笔记图床\QQ图片20201112175118.png)

![](E:\程序人生\个人学习笔记\学习笔记图床\QQ图片20201112175436.png)



- **如何保证消息可靠性-消息丢失**
  - 消息发送出去，由于网络问题没有抵达服务器
    - 做好容错方法(try-catch)，发送消息可能会网络失败，失败后要有重试机制，可记录到数据库，采用定期扫描重发的方式
    - 做好日志记录，每个消息状态是否都被服务器收到都应该记录
    - 做好定期重发，如果消息没有发送成功，定期去数据库扫描未成功的消息进行重发
  - 消息抵达Broker，Broker要将消息写入磁盘(持久化)才算成功。此时Broker尚未持久化完成，宕机。
    - publisher也必须加入确认回调机制，确认成功的消息，修改数据库消息状态。
  - 自动ACK的状态下。消费者收到消息，但没来得及消息然后宕机
    - 一定开启手动ACK，消费成功才移除，失败或者没来得及处理就noAck并重新入队

- 如何保证消息可靠性-消息重复
  - 消息消费成功，事务已经提交，ack时，机器宕机。导致没有ack成功，Broker的消息重新由unack变为ready，并发送给其他消费者
  - 消息消费失败，由于重试机制，自动又将消息发送出去
  - 成功消费，ack时宕机，消息由unack变为ready，Broker又重新发送
    - 消费者的业务消费接口应该设计为幂等性的。比如扣库存有工作单的状态标志
    - 使用防重表(redis/mysql)，发送消息每一个都有业务的唯一标识，处理过就不用处
    - rabbitMQ的每一个消息都有redelivered字段，可以获取是否是被重新投递过来的，而不是第一次投递过来的

- 如何保证消息可靠性-消息积压
  - 消费者宕机积压
  - 消费者消费能力不足积压
  - 发送者发送流量太大
    - 上线更多的消费者，进行正常消费
    - 上线专门的队列消费服务，将消息先批量取出来，记录数据库，离线慢慢处理

#### 2.2.10 秒杀

秒杀具有瞬间高并发的特点，针对这一特点，必须要做限流+异步+缓存(页面静态化)+ 独立部署。

限流方式：
1.前端限流，一些高并发的网站直接在前端页面开始限流，例如：小米的验证码设计
2.nginx 限流，直接负载部分请求到错误的静态页面：令牌算法 漏斗算法
3.网关限流，限流的过滤器

4.代码中使用分布式信号量

5.rabbitmq 限流(能者多劳：chanel，basicQos(1))，保证发挥所有服务器的性能。

**定时任务 - cron表达式**

**限流、熔断、降级**

- 什么是限流
  对打入服务的请求流量进行控制，使服务能够承担不超过自己能力的流量压力

- 什么是熔断
  A服务调用B服务的某个功能，由于网络不稳定问题，或者B服务卡机，导致功能时间超长。如果这样子的次数太多。我们就可以直接将B断路了(A不再请求B接口)，凡是调用B的直接返回降级数据，不必等待B的超长执行。这样B的故障问题，就不会级联影响到A。

- 什么是降级
  整个网站处于流量高峰期，服务器压力剧增，根据当前业务情况及流量，对一些服务和页面进行有策略的降级[停止服务，所有的调用直接返回降级数据]。以此缓解服务器资源的的压力，以保证核心业务的正常运行，同时也保持了客户和大部分客户的得到正确的相应。

  相同点：
  1、为了保证集群大部分服务的可用性和可靠性，防止崩溃，牺牲小我
  2、用户最终都是体验到某个功能不可用
  不同点：
  1、熔断是被调用方故障，触发的系统主动规则
  2、降级是基于全局考虑，停止一些正常服务，释放资源

#### 2.2.11 Sleuth+Zipkin 链路追踪



#### 购物车需求分析

- 用户购物车

- 游客购物车

### 2.3 集群篇开发



